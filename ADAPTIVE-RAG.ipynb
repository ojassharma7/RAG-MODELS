{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33029606-5204-40c1-8844-41e7901b42d2",
   "metadata": {},
   "source": [
    "# ***Adaptive Retrieval-Augmented Generation (RAG)***\n",
    "\n",
    "Simplified idea from the paper https://arxiv.org/abs/2403.14403 and https://arxiv.org/abs/2402.16457.\n",
    "**Adaptive Retrieval-Augmented Generation (Adaptive RAG)** is an advanced approach to information retrieval and response generation that dynamically adjusts its strategy based on the nature of the query. This method enhances the traditional RAG system by tailoring the retrieval process to different types of questions, resulting in more accurate and contextually relevant responses.\n",
    "\n",
    "**Key Features of Adaptive RAG:**\n",
    "- Query Classification: Automatically categorizes queries into types such as factual, analytical, opinion-based, or contextual.\n",
    "- Dynamic Retrieval: Adjusts the number and type of documents retrieved based on the query classification and the model's confidence in answering.\n",
    "- Efficient Resource Use: Optimizes computational resources by retrieving only as much information as necessary to answer the query confidently.\n",
    "- Improved Accuracy: By adapting to each query type, the system can provide more precise and relevant information.\n",
    "\n",
    "**How It Works:**\n",
    "- The system first classifies the incoming query.\n",
    "- Based on the classification, it selects an appropriate retrieval strategy.\n",
    "- The retrieval process (score threshold = 0.9) starts with a minimal set of documents and expands as needed.\n",
    "- If no documents are returned from the vector search , a websearch is launched to ensure the question has an answer.\n",
    "- The retrieved documents are reranked in the order suitable to relevance to the query\n",
    "- The Language Model (LLM) attempts to answer the query with the retrieved information.\n",
    "\n",
    "Adaptive RAG represents a significant advancement in RAG systems, offering a more flexible and efficient approach to handling diverse query types while maintaining high accuracy.\n",
    "\n",
    "This notebook uses [Qdrant](https://qdrant.tech/) with [Fastembed](https://qdrant.github.io/fastembed/) as a vector store , [Synthetic dataset](https://huggingface.co/datasets/atitaarora/adaptive_dataset) as source data, [OpenAI](https://openai.com/) as LLM and [Tavily](https://docs.tavily.com/docs/python-sdk/tavily-search/api-reference) for websearch capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed6f2f6-46b0-4feb-a9d5-5628e4e2d1ea",
   "metadata": {},
   "source": [
    "### **1. Installs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "038f44b3-c403-44f9-8a63-b2f8f5862091",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install qdrant\n",
    "#!pip install openai\n",
    "#!pip install datasets\n",
    "#!pip install \"qdrant-client[fastembed]\"\n",
    "#!pip install tavily-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f48a78-6a41-4aa7-9764-f5403257de36",
   "metadata": {},
   "source": [
    "### **2. Import Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d1913903-820b-4d00-9330-3075cddc4149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from qdrant_client import QdrantClient, models\n",
    "from qdrant_client.http.models import PointStruct\n",
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "from tavily import TavilyClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda9d63f-efd0-4993-bd92-7825360afdb9",
   "metadata": {},
   "source": [
    "### **3. Settings and Configurations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f1ec5cd4-f70f-4a9b-827e-558a7dd01261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the OpenAI API key environment variable\n",
    "OPENAI_API_KEY= os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "#Set up Tavily API for websearch\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "#Collection Name for the notebook\n",
    "COLLECTION_NAME = \"adaptive_retrieval\"\n",
    "\n",
    "# Initialize Qdrant client\n",
    "client = QdrantClient(location=\":memory:\")\n",
    "\n",
    "# Initialize OpenAI client\n",
    "openai_client = OpenAI()\n",
    "\n",
    "#Initialise Tavily client\n",
    "tavily_client = TavilyClient(api_key=TAVILY_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "4269c623-1b50-405f-8eff-ccfea07de1e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CollectionsResponse(collections=[])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check if Collection already exists\n",
    "client.get_collections()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca2cdbb-2d21-4343-aade-9837c2c89237",
   "metadata": {},
   "source": [
    "### **4. Dataset config to be used in the notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "94584009-ae93-49b0-9678-c46d00549078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"atitaarora/adaptive_dataset\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "3a47f441-b1dc-4a35-982e-b75d4a107077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb1335a9-1a42-4050-8a78-a88a3eca7a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'title: Climate Change Impact Analysis,content: Climate change is causing significant environmental shifts globally. Rising temperatures lead to melting ice caps, rising sea levels, and more frequent extreme weather events. This affects ecosystems, agriculture, and human settlements. Mitigation strategies include reducing greenhouse gas emissions and developing sustainable energy sources.',\n",
       " 'metadata': {'content': 'Climate change is causing significant environmental shifts globally. Rising temperatures lead to melting ice caps, rising sea levels, and more frequent extreme weather events. This affects ecosystems, agriculture, and human settlements. Mitigation strategies include reducing greenhouse gas emissions and developing sustainable energy sources.',\n",
       "  'context': None,\n",
       "  'title': 'Climate Change Impact Analysis'}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5567363c-e013-405e-88a5-2a34ba1ad725",
   "metadata": {},
   "source": [
    "### **5. Process dataset for ingestion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "29ccee7a-a94f-4ad1-b5b2-72c29919bd10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 620.45it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from langchain.docstore.document import Document as LangchainDocument\n",
    "\n",
    "## Dataset to langchain document\n",
    "langchain_docs = [\n",
    "    LangchainDocument(page_content=doc[\"content\"], metadata=doc[\"metadata\"])\n",
    "    for doc in tqdm(dataset)\n",
    "]\n",
    "\n",
    "len(langchain_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "121e7f77-0403-4173-bdcd-9683669760f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'content': 'Climate change is causing significant environmental shifts globally. Rising temperatures lead to melting ice caps, rising sea levels, and more frequent extreme weather events. This affects ecosystems, agriculture, and human settlements. Mitigation strategies include reducing greenhouse gas emissions and developing sustainable energy sources.', 'context': None, 'title': 'Climate Change Impact Analysis'}, page_content='title: Climate Change Impact Analysis,content: Climate change is causing significant environmental shifts globally. Rising temperatures lead to melting ice caps, rising sea levels, and more frequent extreme weather events. This affects ecosystems, agriculture, and human settlements. Mitigation strategies include reducing greenhouse gas emissions and developing sustainable energy sources.')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langchain_docs[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96277299-61d1-4f09-bed7-5fbac4b6f449",
   "metadata": {},
   "source": [
    "### **6. Document Embedding configuration and processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "b5ba9430-9bac-4176-b333-4f0000ee2ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ef09dd0fe82446cbf6caadb95a7137e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26afe0dd03fd4e43bf8346befe79a87e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_optimized.onnx:   0%|          | 0.00/66.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "998d380cce794f6084136a84d09973c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "069c410e30c84c0db5ae9eaa0dc02c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7b65f04bd144bcea5da11f3238e85be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/706 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63321f767ae74e8ebe75d58abf8c142c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastembed.embedding import TextEmbedding\n",
    "embedding_model = TextEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "dc9ab3b0-29f9-4da6-8c5d-d212cd06dac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_document_embeddings(docs):\n",
    "    docs_contents = []\n",
    "    docs_metadatas = []\n",
    "\n",
    "    for doc in docs:\n",
    "        if hasattr(doc, 'page_content') and hasattr(doc, 'metadata'):\n",
    "            docs_contents.append(doc.page_content)\n",
    "            docs_metadatas.append(doc.metadata)\n",
    "        else:\n",
    "            # Handle the case where attributes are missing\n",
    "            print(\"Warning: Some documents do not have 'content' or 'metadata' attributes.\")\n",
    "    \n",
    "    print(\"data-size : \",len(docs))\n",
    "    print(\"content : \",len(docs_contents))\n",
    "    print(\"metadata : \",len(docs_metadatas))\n",
    "    return (docs_contents,docs_metadatas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "4c1f936a-70d0-4208-8381-9f8a0ee7283d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data-size :  8\n",
      "content :  8\n",
      "metadata :  8\n"
     ]
    }
   ],
   "source": [
    "docs_contents , docs_metadatas = process_document_embeddings(langchain_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6a78a9-09c1-41f6-85ad-aa0760110a54",
   "metadata": {},
   "source": [
    "### **7. Adding documents to Qdrant**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "53057a0b-fc85-4647-8a08-a70b668c4691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a7655fe59a7749668e723a110f53193b',\n",
       " '232b75f8f68d49caac14cfd37e62a33d',\n",
       " '130e2292a9ff4019bf55b97979e6fca5',\n",
       " '5cc839972ff64466879057b0d218e8d3',\n",
       " 'fec038990b0e40b98979574de447bd5e',\n",
       " '5421d47447aa42f9b1c55853c097902d',\n",
       " '0b3e0c9c8e624dc087fa0297c7f8836e',\n",
       " '315c1d6d875a47e18329ee52fb3d2d81']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.add(collection_name=COLLECTION_NAME, metadata=docs_metadatas, documents=docs_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "cdad7e44-6141-43ef-b31c-282770f48805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QueryResponse(id='a7655fe59a7749668e723a110f53193b', embedding=None, sparse_embedding=None, metadata={'document': 'title: The Solar System, content: The solar system consists of the Sun and everything that orbits around it, including eight planets, dwarf planets, and countless smaller objects. The planets in order from the Sun are Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune.', 'content': 'The solar system consists of the Sun and everything that orbits around it, including eight planets, dwarf planets, and countless smaller objects. The planets in order from the Sun are Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune.', 'context': None, 'title': 'The Solar System'}, document='title: The Solar System, content: The solar system consists of the Sun and everything that orbits around it, including eight planets, dwarf planets, and countless smaller objects. The planets in order from the Sun are Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune.', score=0.8979522095419471), QueryResponse(id='232b75f8f68d49caac14cfd37e62a33d', embedding=None, sparse_embedding=None, metadata={'document': \"title: World War II Timeline, content: World War II lasted from 1939 to 1945. Key events include Germany's invasion of Poland in 1939, the attack on Pearl Harbor in 1941, D-Day in 1944, and the atomic bombings of Hiroshima and Nagasaki in 1945.\", 'content': \"World War II lasted from 1939 to 1945. Key events include Germany's invasion of Poland in 1939, the attack on Pearl Harbor in 1941, D-Day in 1944, and the atomic bombings of Hiroshima and Nagasaki in 1945.\", 'context': None, 'title': 'World War II Timeline'}, document=\"title: World War II Timeline, content: World War II lasted from 1939 to 1945. Key events include Germany's invasion of Poland in 1939, the attack on Pearl Harbor in 1941, D-Day in 1944, and the atomic bombings of Hiroshima and Nagasaki in 1945.\", score=0.7448280782643195)]\n"
     ]
    }
   ],
   "source": [
    "## Test query\n",
    "search_result = client.query(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    query_text=\"solar system\",\n",
    "    limit=2\n",
    ")\n",
    "print(search_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8465a9-2c2d-48a3-8d74-63ab2f175c3a",
   "metadata": {},
   "source": [
    "### **8. Building Adaptive RAG blocks**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbafb5f0-0981-4ad5-8b64-05486327461c",
   "metadata": {},
   "source": [
    "### **classify_query()**\n",
    "\n",
    "Method to classify the query as Factual , Analytical , Opinion bases or Contextual to user history so it can be processed accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "58d60541-31e3-4b5a-a7e1-369daea4d94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_query(query):\n",
    "    prompt = f\"Classify the following query into one of these categories: Factual, Analytical, Opinion, or Contextual.\\nQuery: {query}\\nCategory:\"\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    print(\"Identified query type: \" , response.choices[0].message.content.strip())\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e71996-2b0b-46b3-8bbf-26cd82edad18",
   "metadata": {},
   "source": [
    "### **web_search()**\n",
    "\n",
    "Method to launch the websearch for the given query to ensure it is answered with latest information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "9f955609-c44a-4492-9027-809a40e19961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_search(query):\n",
    "    #context = tavily_client.get_search_context(query,max_results=2,results=[\"title\",\"content\",\"score\"])\n",
    "    context = tavily_client.search(query,search_depth=\"advanced\", max_results=2,results=[\"title\",\"content\",\"score\"])[\"results\"]\n",
    "    #print(context)\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "b4ae9164-5584-491d-85da-a0b0e36f44ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#web_search(\"What happened during the Burning Man floods?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d8aff4-f64c-4b14-8f53-165e16b17e75",
   "metadata": {},
   "source": [
    "### **factual_strategy()**\n",
    "\n",
    "Method to improvise/enhance the user query using LLM and launch a factual/factoid search that can be supported through direct vector search from our vector store.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "758bf143-5fc6-4d49-92df-6cf304220f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def factual_strategy(query):\n",
    "    enhanced_query = openai_client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": f\"Enhance this query for better precision: {query}\"}]\n",
    "    ).choices[0].message.content\n",
    "    \n",
    "    search_result = client.query(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        query_text=query,\n",
    "        limit=2,\n",
    "        score_threshold=0.9\n",
    "    )\n",
    "    \n",
    "    return [hit.metadata for hit in search_result]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df27be3f-fc63-47ed-a1d2-b5e07bcc1b74",
   "metadata": {},
   "source": [
    "### **analytical_strategy()**\n",
    "\n",
    "Method to analyse the user query using LLM where it generates 2 sub queries to cover different aspects of the questions followed by semantic search to our vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "45887979-ec24-4666-9436-f90a5b347686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analytical_strategy(query):\n",
    "    sub_queries = openai_client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": f\"Generate 2 sub-queries to cover different aspects of this query: {query}\"}]\n",
    "    ).choices[0].message.content.split(\"\\n\")\n",
    "    print(sub_queries)\n",
    "    all_results = []\n",
    "    for sub_query in sub_queries:\n",
    "        search_result = client.query(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            query_text=sub_query,\n",
    "            limit=1\n",
    "        )\n",
    "        all_results.extend([hit.metadata for hit in search_result])\n",
    "    \n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66463b6-51c2-4608-a577-a4b7d6d489f9",
   "metadata": {},
   "source": [
    "### **opinion_strategy()**\n",
    "\n",
    "Method to generate 2 different viewpoints of the user query using LLM and collect respective results for each viewpoint through semantic search from our vector store to prepare a rounded answer to the user query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fc8026f7-4dec-4a22-8101-b1dd61d7aec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def opinion_strategy(query):\n",
    "    viewpoints = openai_client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": f\"Identify 2 different viewpoints on this topic: {query}\"}]\n",
    "    ).choices[0].message.content.split(\"\\n\")\n",
    "    \n",
    "    all_results = []\n",
    "    for viewpoint in viewpoints:\n",
    "        search_result = client.query(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            query_text=viewpoint,\n",
    "            limit=1\n",
    "        )\n",
    "        all_results.extend([hit.metadata for hit in search_result])\n",
    "    \n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4674bc-7730-4117-8348-dac504fc0c74",
   "metadata": {},
   "source": [
    "### **contexual_strategy()**\n",
    "\n",
    "Method to accomodate contexual information along with the user query to filter and process the most appropriate responses to the user query using semantic search with filters from our vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a4db3ad2-be72-451d-852b-1e18d01206b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client.models import Filter, FieldCondition, Range\n",
    "\n",
    "def contextual_strategy(query, user_context):\n",
    "    contextualized_query = openai_client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": f\"Incorporate this user context into the query: {user_context}\\nQuery: {query}\"}]\n",
    "    ).choices[0].message.content\n",
    "    \n",
    "    if 'location' in context:\n",
    "        city_filter = models.Filter(\n",
    "            must=[\n",
    "                models.FieldCondition(\n",
    "                    key=\"context.location\", \n",
    "                    match=models.MatchValue(value=context['location'])\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    search_result = client.query(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        query_text=query,\n",
    "        query_filter=city_filter,\n",
    "        limit=2\n",
    "    )\n",
    "    print(search_result)\n",
    "    return [hit.metadata for hit in search_result]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40c2177-e82f-40f9-b47d-83979e94a642",
   "metadata": {},
   "source": [
    "### **rank_documents()**\n",
    "\n",
    "Rerank the documents retrieved from the vector store ,  per the perceived relevance from LLM leveraging user query.\n",
    "\n",
    "Note : Can leverage reranker model from providers like Jina , Cohere and Mixedbread.\n",
    "\n",
    "### **generate_response()** \n",
    "\n",
    "Bring together the relevent retrieved context from vector store / web to generate a suitable answer for user query.\n",
    "\n",
    "Note : Can leverage Prompt Experimentation, if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "53e7b1c9-4a84-4c48-b1f1-dda7a01387ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_documents(documents, query):\n",
    "    document_contents = [doc['content'] for doc in documents]\n",
    "    ranked_docs = openai_client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": f\"Rank these documents by relevance to the query: {query}\\n\\nDocuments:\\n\" + \"\\n\".join(document_contents)}\n",
    "        ]\n",
    "    ).choices[0].message.content.split(\"\\n\")\n",
    "    return ranked_docs\n",
    "\n",
    "def generate_response(query, context):\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant. Use the provided context to answer the user's query.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Context:\\n{context}\\n\\nQuery: {query}\"}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c55c0b-6ab6-4216-a59a-d58395c81894",
   "metadata": {},
   "source": [
    "### **9. Adaptive RAG Pipeline**\n",
    "\n",
    "This brings together all our bit and pieces together to form a desired RAG pipeline that adapts per the user query and answers them in the most appropriate way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "4aaa25f4-15a3-4272-9107-d3c88fb26572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_rag(query, user_context=None):\n",
    "    query_type = classify_query(query)\n",
    "    \n",
    "    if query_type == \"Factual\":\n",
    "        retrieved_docs = factual_strategy(query)\n",
    "    elif query_type == \"Analytical\":\n",
    "        retrieved_docs = analytical_strategy(query)\n",
    "    elif query_type == \"Opinion\":\n",
    "        retrieved_docs = opinion_strategy(query)\n",
    "    elif query_type == \"Contextual\":\n",
    "        retrieved_docs = contextual_strategy(query, user_context)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid query type\")\n",
    "    \n",
    "    if len(retrieved_docs) == 0:\n",
    "        retrieved_docs = web_search(query)\n",
    "        \n",
    "    ranked_docs = rank_documents(retrieved_docs, query)\n",
    "    context = \"\\n\".join(ranked_docs[:2])  # Use top 2 ranked documents\n",
    "    print(\"context: \" , context)\n",
    "    response = generate_response(query, context)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02542c6-45fb-4bcb-9031-f40a8407fd58",
   "metadata": {},
   "source": [
    "### **10. Experiments to test our Adapative RAG Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "f11c4259-4564-47a4-8108-75bcf02734bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified query type:  Factual\n",
      "Identified query type:  Factual\n",
      "context:  1. Oct. 22, 2024 / 3:00 AM UPI Almanac for Tuesday, Oct. 22, 2024 - Mentions the date in question\n",
      "2. Updated October 22, 2024 at 11:30 a.m.U.S. President John F. Kennedy announced that American reconnaissance planes discovered Soviet nuclear weapons in Cuba, marking the beginning of the Cuban Missile Crisis on this day in 1962. - Mentions a significant event that happened on the same date in history\n",
      "On October 22, 2024, the UPI Almanac mentions the date itself. Additionally, that day in history, on the same date in 1962, U.S. President John F. Kennedy announced the beginning of the Cuban Missile Crisis after American reconnaissance planes discovered Soviet nuclear weapons in Cuba.\n"
     ]
    }
   ],
   "source": [
    "## The one with Websearch\n",
    "query_test = \"What happened on 22nd oct 2024\"\n",
    "classify_query(query_test)\n",
    "response_test = adaptive_rag(query_test)\n",
    "print(response_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5e08664b-f84a-42a5-8de6-eb2716d98d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified query type:  Analytical\n",
      "context:  1. Climate Change Impact Analysis\n",
      "2. The Future of Work: Remote vs. Office-based\n",
      "Pros of renewable energy:\n",
      "1. Environmentally friendly: It helps reduce greenhouse gas emissions that contribute to climate change.\n",
      "2. Renewable and sustainable: Resources like sunlight, wind, and water are continuously replenished.\n",
      "3. Energy security: It reduces dependence on finite fossil fuel resources.\n",
      "4. Job creation: The renewable energy sector creates jobs and promotes economic growth.\n",
      "5. Cost-effective: Over time, renewable energy can be more cost-effective than fossil fuels.\n",
      "\n",
      "Cons of renewable energy:\n",
      "1. Intermittency: Some renewable sources like wind and solar energy can be intermittent, depending on weather conditions.\n",
      "2. Initial costs: The upfront costs of installing renewable energy systems can be expensive.\n",
      "3. Land use: Some renewable energy projects require significant land use, which may impact ecosystems.\n",
      "4. Energy storage: Storage technology needs to improve to store excess energy generated for when renewable sources are not available.\n",
      "5. Aesthetics: Some renewable energy installations, like wind turbines, can raise concerns about visual impact in certain locations.\n"
     ]
    }
   ],
   "source": [
    "## Example usage with Analytical Strategy\n",
    "query = \"What are the pros and cons of renewable energy?\"\n",
    "response = adaptive_rag(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "015feec2-bb4b-4572-a2ec-b9d3e25d29ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified query type:  Contextual\n",
      "[QueryResponse(id='4080153504ae4b5f921c64dcb487644f', embedding=None, sparse_embedding=None, metadata={'document': \"title: Vegetarian Restaurants in London,content: London boasts numerous vegetarian dining options. Mildreds offers diverse international cuisine. The Gate serves gourmet vegetarian dishes. For quick bites, try Pret A Manger's vegetarian options. Many traditional pubs now offer extensive vegetarian menus to cater to changing dietary preferences.\", 'content': \"London boasts numerous vegetarian dining options. Mildreds offers diverse international cuisine. The Gate serves gourmet vegetarian dishes. For quick bites, try Pret A Manger's vegetarian options. Many traditional pubs now offer extensive vegetarian menus to cater to changing dietary preferences.\", 'context': {'dietary_preference': 'vegetarian', 'location': 'London'}, 'title': 'Vegetarian Restaurants in London'}, document=\"title: Vegetarian Restaurants in London,content: London boasts numerous vegetarian dining options. Mildreds offers diverse international cuisine. The Gate serves gourmet vegetarian dishes. For quick bites, try Pret A Manger's vegetarian options. Many traditional pubs now offer extensive vegetarian menus to cater to changing dietary preferences.\", score=0.803106781151779)]\n",
      "context:  1. The Gate serves gourmet vegetarian dishes.\n",
      "2. Mildreds offers diverse international cuisine.\n",
      "Based on the context you provided, two good restaurants that you might enjoy are The Gate for gourmet vegetarian dishes and Mildreds for diverse international cuisine. Both restaurants offer unique and delicious options for you to explore.\n"
     ]
    }
   ],
   "source": [
    "## Example usage with Contexual Strategy\n",
    "query_2 = \"What are good restaurants per my context?\"\n",
    "user_context = {\"location\":\"New York\"}\n",
    "response_2 = adaptive_rag(query_2,user_context)\n",
    "print(response_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "db3bf8cb-8418-469f-bc10-57c97286b424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified query type:  Opinion\n",
      "context:  1. The COVID-19 pandemic has accelerated the shift towards remote work. Proponents argue it offers better work-life balance and increased productivity. Critics contend it can lead to isolation and hinder collaboration. The future likely involves a hybrid model, balancing the benefits of both remote and office-based work.\n",
      "The debate of whether remote work is better than office-based work depends on different perspectives and individual preferences. Remote work can offer benefits such as better work-life balance, increased productivity, and decreased commuting time. On the other hand, office-based work can foster better collaboration and social interaction among colleagues. The future of work is likely to involve a hybrid model that combines the advantages of both remote and office-based work. Ultimately, the best approach may vary depending on the nature of the job, individual preferences, and organizational dynamics.\n"
     ]
    }
   ],
   "source": [
    "## Example usage with Opinion Based Strategy\n",
    "query_6 = \"Is remote work better or office based?\"\n",
    "response_6 = adaptive_rag(query_6)\n",
    "print(response_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "11cf68ea-1741-48ed-8121-481b2907c783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified query type:  Factual\n",
      "context:  1. World War II lasted from 1939 to 1945. Key events include Germany's invasion of Poland in 1939, the attack on Pearl Harbor in 1941, D-Day in 1944, and the atomic bombings of Hiroshima and Nagasaki in 1945. \n",
      "\n",
      "World War II lasted from 1939 to 1945 and consisted of several key events that shaped the conflict. Some of the major events in the World War II timeline include Germany's invasion of Poland in 1939, the attack on Pearl Harbor by Japan in 1941, D-Day in 1944, which marked the Allied invasion of Normandy, France, and the atomic bombings of Hiroshima and Nagasaki in 1945 by the United States. These events are crucial to understanding the progression and impact of World War II.\n"
     ]
    }
   ],
   "source": [
    "## Example usage with Factual Strategy\n",
    "query_4 = \"Tell me a bit about World War II Timeline?\"\n",
    "response_4 = adaptive_rag(query_4)\n",
    "print(response_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6923c684-f3fe-4910-b65d-dd523fcd3288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified query type:  Analytical\n",
      "['Sub-query 1: What are the specific tasks being automated in different industries?', '', 'SELECT industry, automation_impact', 'FROM automation_data', \"WHERE automation_impact = 'positive';\", '', 'Sub-query 2: How are workers adapting to automation in the workplace?', '', 'SELECT worker_response', 'FROM automation_impact', \"WHERE automation_impact = 'negative';\"]\n",
      "context:  1. Automation is reshaping the job market. While it increases productivity and efficiency, it also displaces certain types of jobs. This leads to a shift in skill requirements, with a growing demand for tech-savvy workers. The impact varies across industries, with manufacturing and retail being significantly affected.\n",
      "\n",
      "Automation is significantly impacting the job market by increasing productivity and efficiency. However, it also results in the displacement of certain jobs, leading to a shift in skill requirements. This shift is causing a growing demand for tech-savvy workers. The impact of automation varies across industries, with sectors like manufacturing and retail experiencing significant changes in the nature of work.\n"
     ]
    }
   ],
   "source": [
    "## Another Example usage with Analytical Strategy\n",
    "query_3 = \"How is automation affecting our work?\"\n",
    "response_3 = adaptive_rag(query_3)\n",
    "print(response_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6daf1e89-10f7-4644-8b6f-d7d080b68e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified query type:  Analytical\n",
      "['Sub-query 1: ', '- Evaluate the correlation between rising temperatures and greenhouse gas emissions over time. This sub-query would involve analyzing historical data on global temperatures and greenhouse gas emissions to determine if there is a significant relationship between the two factors.', '', 'Sub-query 2: ', '- Examine the impact of rising temperatures on key environmental indicators such as melting ice caps, rising sea levels, and shifts in animal habitats. This sub-query would involve studying environmental data and research studies to assess the direct effects of rising temperatures on various aspects of the climate and ecosystem.']\n",
      "context:  1. Climate change is causing significant environmental shifts globally. Rising temperatures lead to melting ice caps, rising sea levels, and more frequent extreme weather events. This affects ecosystems, agriculture, and human settlements. Mitigation strategies include reducing greenhouse gas emissions and developing sustainable energy sources.\n",
      "\n",
      "Yes, rising temperatures are a key aspect of climate change. The increase in global temperatures is a clear indicator of the changing climate, leading to various environmental impacts such as melting ice caps, rising sea levels, and extreme weather events. Addressing rising temperatures and their effects is crucial in mitigating the overall impacts of climate change.\n"
     ]
    }
   ],
   "source": [
    "## Another Example usage with Analytical Strategy\n",
    "query_5 = \"Is rising temparature impacting climate change?\"\n",
    "response_5 = adaptive_rag(query_5)\n",
    "print(response_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f401f2-a2ef-44e0-bfe3-9d3708fb8f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
